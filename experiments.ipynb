{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ancient-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-display",
   "metadata": {},
   "source": [
    "# PLEASE\n",
    "Run only what you need. Thanks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-privilege",
   "metadata": {},
   "source": [
    "## Simultaneous max and min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "musical-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(x):\n",
    "    y = np.max(x[:, None, :] * np.array([-1, 1])[:, None, None], axis=2)\n",
    "    #y[:, 0] *= -1\n",
    "    return y\n",
    "\n",
    "def minmax2(x):\n",
    "    return np.concatenate([np.min(x, axis=1)[:,None], np.max(x, axis=1)[:,None]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "organic-stadium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633 ms ± 90.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "267 ms ± 19.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(10000000).reshape(-1,50,2)\n",
    "\n",
    "#assert np.allclose(minmax(x), minmax2(x))\n",
    "\n",
    "%timeit minmax(x)\n",
    "%timeit minmax2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-sacramento",
   "metadata": {},
   "source": [
    "## `np.nan` is as performant as a shorter matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "downtown-clearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 2)\n",
      "9.49 ms ± 1.15 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "(1000000, 2)\n",
      "21 ms ± 3.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "(1000000, 2)\n",
      "21 ms ± 2.16 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(1000000).reshape(-1,2)\n",
    "print(x.shape)\n",
    "\n",
    "%timeit x + 2 - np.array([2,20])[None]\n",
    "\n",
    "y = np.vstack([x, np.full((500000, 2), np.nan)])\n",
    "print(y.shape)\n",
    "\n",
    "%timeit y + 2 - np.array([2,20])[None]\n",
    "\n",
    "z = np.vstack([x, x])\n",
    "print(z.shape)\n",
    "\n",
    "%timeit z + 2 - np.array([2,20])[None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-establishment",
   "metadata": {},
   "source": [
    "## Best way to achieve all `False` in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "seasonal-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.full((10000,1000), False)\n",
    "x[2,5] = True\n",
    "x[1000,10] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ordered-petersburg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 ms ± 1.5 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "1.24 ms ± 78.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "1.14 ms ± 5.85 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "4.26 ms ± 39.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.all(np.logical_not(x), axis=1)\n",
    "%timeit np.logical_not(np.any(x, axis=1))\n",
    "%timeit ~np.any(x, axis=1)\n",
    "%timeit (~x).all(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-patch",
   "metadata": {},
   "source": [
    "## Is `map_blocks` better than the standard operation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "determined-disaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple subtraction\n",
      "9.77 s ± 2.38 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "8.31 s ± 873 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Some references to y\n",
      "14.2 s ± 1.56 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "14.9 s ± 1.49 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Multiple references to y\n",
      "28.9 s ± 3.69 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "10.7 s ± 458 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "NumPy function\n",
      "10.5 s ± 1.54 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "9.45 s ± 976 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "y = da.from_array(np.ones((1000,1000,200)))\n",
    "\n",
    "print('Simple subtraction')\n",
    "%timeit (y - 10).compute()\n",
    "%timeit y.map_blocks(lambda x: x - 10).compute()\n",
    "\n",
    "print('Some references to y')\n",
    "%timeit (y - 10 + 2*y).compute()\n",
    "%timeit y.map_blocks(lambda x: x - 10 + 2*x).compute()\n",
    "\n",
    "print('Multiple references to y')\n",
    "%timeit (y + 2*y - 3*y + 4*y - 5*y).compute()\n",
    "%timeit y.map_blocks(lambda x: x + 2*x - 3*x + 4*x - 5*x).compute()\n",
    "\n",
    "print('NumPy function')\n",
    "%timeit (np.exp(y+2)).compute()\n",
    "%timeit y.map_blocks(lambda x: np.exp(x)).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-integrity",
   "metadata": {},
   "source": [
    "## Is `map_blocks` better/worse than the corresponding Dask function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "improved-warehouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282 ms ± 87.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "178 ms ± 18.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "y = da.from_array(np.ones((1000,1000,20)) + 0.5)\n",
    "\n",
    "%timeit y.map_blocks(lambda x: np.floor(x)).compute()\n",
    "%timeit da.floor(y).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-texas",
   "metadata": {},
   "source": [
    "## Does `np.unique` work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "indirect-valley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 9997, 9998, 9999])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = da.from_array(np.arange(10000))\n",
    "da.unique(y, return_index=True)[1].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-backup",
   "metadata": {},
   "source": [
    "## What about `argsort`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "surgical-secondary",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'dask.array' has no attribute 'argsort'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e955ea77c534>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'dask.array' has no attribute 'argsort'"
     ]
    }
   ],
   "source": [
    "y = da.from_array(np.arange(10000))\n",
    "y = y[da.argsort(y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-license",
   "metadata": {},
   "source": [
    "## What's the best way to create a matrix such that different submatrices are filled with different rules?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "coated-dylan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.02 ms ± 24.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "8.46 ms ± 73.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "def fill1():\n",
    "    x = np.zeros((9900, 100), dtype=float)\n",
    "    for i in range(1,100):\n",
    "        x[(i-1)*100:i*100] = i*np.arange(i*100-100,i*100)[::-1]\n",
    "    return x\n",
    "\n",
    "def fill2():\n",
    "    return np.vstack([\n",
    "        np.repeat(i*np.arange(i*100-100,i*100)[::-1][None], repeats=100, axis=0) for i in range(1,100)\n",
    "    ])\n",
    "\n",
    "\n",
    "%timeit fill1()\n",
    "%timeit fill2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-southeast",
   "metadata": {},
   "source": [
    "## What's the best way to fill a matrix taking values from a vector according to some indexing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "molecular-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def generate_binified_points_matrix(pts, indexes, bins_size):\n",
    "    zs = np.zeros((bins_size - 1, pts.shape[1]))\n",
    "    for idx in range(len(indexes)):\n",
    "        idx = indexes[idx]\n",
    "        yield pts[idx], zs[: bins_size - len(idx)]\n",
    "        \n",
    "def bins1(pts, indexes_inside_bins, biggest_bin):\n",
    "    return np.vstack(\n",
    "            tuple(chain.from_iterable(\n",
    "                generate_binified_points_matrix(\n",
    "                    pts, indexes_inside_bins, biggest_bin\n",
    "                )\n",
    "            ))\n",
    "        ).reshape(len(indexes_inside_bins), biggest_bin, pts.shape[1])\n",
    "\n",
    "def bins2(pts, indexes_inside_bins, biggest_bin):\n",
    "    nbins = len(indexes_inside_bins)\n",
    "    bins = np.zeros((nbins, biggest_bin, pts.shape[1]))\n",
    "    for bin_idx in range(nbins):\n",
    "        ps = pts[indexes_inside_bins[bin_idx]]\n",
    "        bins[bin_idx, : len(ps)] = ps\n",
    "    return bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "voluntary-blond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n components = 1\n",
      "172 µs ± 2.28 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "116 µs ± 933 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "n components = 2\n",
      "408 µs ± 770 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "346 µs ± 962 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "n components = 3\n",
      "372 µs ± 1.53 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "329 µs ± 31.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "n components = 5\n",
      "437 µs ± 3.59 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "359 µs ± 1.64 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "n components = 10\n",
      "1.09 ms ± 3.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "963 µs ± 2.06 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "n components = 100\n",
      "12.5 ms ± 676 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "9.85 ms ± 136 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "for n_components in (1,2,3,5,10,100):\n",
    "    pts = np.random.rand(10000, n_components)\n",
    "    indexes_inside_bins = np.arange(10000)[::-1]\n",
    "    split_sizes = [100,200,400,50, 50, 1000, 1500, 500, 900, 100, 500, 1000, 500, 100, 200, 200, \n",
    "                   500, 1000, 1, 1, 1, 7, 80, 5]\n",
    "    indexes_inside_bins = np.split(indexes_inside_bins, np.cumsum(split_sizes))\n",
    "\n",
    "    M = np.max(split_sizes)\n",
    "    \n",
    "    print('n components = {}'.format(n_components))\n",
    "    %timeit bins1(pts, indexes_inside_bins, M)\n",
    "    %timeit bins2(pts, indexes_inside_bins, M)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
