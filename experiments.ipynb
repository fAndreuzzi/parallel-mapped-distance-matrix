{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ancient-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dask.array as da\n",
    "from dask.distributed import Client, as_completed\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-display",
   "metadata": {},
   "source": [
    "# PLEASE\n",
    "Run only what you need. Thanks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-privilege",
   "metadata": {},
   "source": [
    "## Simultaneous max and min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(x):\n",
    "    y = np.max(x[:, None, :] * np.array([-1, 1])[:, None, None], axis=2)\n",
    "    #y[:, 0] *= -1\n",
    "    return y\n",
    "\n",
    "def minmax2(x):\n",
    "    return np.concatenate([np.min(x, axis=1)[:,None], np.max(x, axis=1)[:,None]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-stadium",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10000000).reshape(-1,50,2)\n",
    "\n",
    "#assert np.allclose(minmax(x), minmax2(x))\n",
    "\n",
    "%timeit minmax(x)\n",
    "%timeit minmax2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-sacramento",
   "metadata": {},
   "source": [
    "## `np.nan` is as performant as a shorter matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1000000).reshape(-1,2)\n",
    "print(x.shape)\n",
    "\n",
    "%timeit x + 2 - np.array([2,20])[None]\n",
    "\n",
    "y = np.vstack([x, np.full((500000, 2), np.nan)])\n",
    "print(y.shape)\n",
    "\n",
    "%timeit y + 2 - np.array([2,20])[None]\n",
    "\n",
    "z = np.vstack([x, x])\n",
    "print(z.shape)\n",
    "\n",
    "%timeit z + 2 - np.array([2,20])[None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-establishment",
   "metadata": {},
   "source": [
    "## Best way to achieve all `False` in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.full((10000,1000), False)\n",
    "x[2,5] = True\n",
    "x[1000,10] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit np.all(np.logical_not(x), axis=1)\n",
    "%timeit np.logical_not(np.any(x, axis=1))\n",
    "%timeit ~np.any(x, axis=1)\n",
    "%timeit (~x).all(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-patch",
   "metadata": {},
   "source": [
    "## Is `map_blocks` better than the standard operation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = da.from_array(np.ones((1000,1000,200)))\n",
    "\n",
    "print('Simple subtraction')\n",
    "%timeit (y - 10).compute()\n",
    "%timeit y.map_blocks(lambda x: x - 10).compute()\n",
    "\n",
    "print('Some references to y')\n",
    "%timeit (y - 10 + 2*y).compute()\n",
    "%timeit y.map_blocks(lambda x: x - 10 + 2*x).compute()\n",
    "\n",
    "print('Multiple references to y')\n",
    "%timeit (y + 2*y - 3*y + 4*y - 5*y).compute()\n",
    "%timeit y.map_blocks(lambda x: x + 2*x - 3*x + 4*x - 5*x).compute()\n",
    "\n",
    "print('NumPy function')\n",
    "%timeit (np.exp(y+2)).compute()\n",
    "%timeit y.map_blocks(lambda x: np.exp(x)).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-integrity",
   "metadata": {},
   "source": [
    "## Is `map_blocks` better/worse than the corresponding Dask function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = da.from_array(np.ones((1000,1000,20)) + 0.5)\n",
    "\n",
    "%timeit y.map_blocks(lambda x: np.floor(x)).compute()\n",
    "%timeit da.floor(y).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-texas",
   "metadata": {},
   "source": [
    "## Does `np.unique` work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-valley",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = da.from_array(np.arange(10000))\n",
    "da.unique(y, return_index=True)[1].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-backup",
   "metadata": {},
   "source": [
    "## What about `argsort`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = da.from_array(np.arange(10000))\n",
    "y = y[da.argsort(y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-license",
   "metadata": {},
   "source": [
    "## What's the best way to create a matrix such that different submatrices are filled with different rules?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill1():\n",
    "    x = np.zeros((9900, 100), dtype=float)\n",
    "    for i in range(1,100):\n",
    "        x[(i-1)*100:i*100] = i*np.arange(i*100-100,i*100)[::-1]\n",
    "    return x\n",
    "\n",
    "def fill2():\n",
    "    return np.vstack([\n",
    "        np.repeat(i*np.arange(i*100-100,i*100)[::-1][None], repeats=100, axis=0) for i in range(1,100)\n",
    "    ])\n",
    "\n",
    "\n",
    "%timeit fill1()\n",
    "%timeit fill2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-southeast",
   "metadata": {},
   "source": [
    "## What's the best way to fill a matrix taking values from a vector according to some indexing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def generate_binified_points_matrix(pts, indexes, bins_size):\n",
    "    zs = np.zeros((bins_size - 1, pts.shape[1]))\n",
    "    for idx in range(len(indexes)):\n",
    "        idx = indexes[idx]\n",
    "        yield pts[idx], zs[: bins_size - len(idx)]\n",
    "        \n",
    "def bins1(pts, indexes_inside_bins, biggest_bin):\n",
    "    return np.vstack(\n",
    "            tuple(chain.from_iterable(\n",
    "                generate_binified_points_matrix(\n",
    "                    pts, indexes_inside_bins, biggest_bin\n",
    "                )\n",
    "            ))\n",
    "        ).reshape(len(indexes_inside_bins), biggest_bin, pts.shape[1])\n",
    "\n",
    "def bins2(pts, indexes_inside_bins, biggest_bin):\n",
    "    nbins = len(indexes_inside_bins)\n",
    "    bins = np.zeros((nbins, biggest_bin, pts.shape[1]))\n",
    "    for bin_idx in range(nbins):\n",
    "        ps = pts[indexes_inside_bins[bin_idx]]\n",
    "        bins[bin_idx, : len(ps)] = ps\n",
    "    return bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_components in (1,2,3,5,10,100):\n",
    "    pts = np.random.rand(10000, n_components)\n",
    "    indexes_inside_bins = np.arange(10000)[::-1]\n",
    "    split_sizes = [100,200,400,50, 50, 1000, 1500, 500, 900, 100, 500, 1000, 500, 100, 200, 200, \n",
    "                   500, 1000, 1, 1, 1, 7, 80, 5]\n",
    "    indexes_inside_bins = np.split(indexes_inside_bins, np.cumsum(split_sizes))\n",
    "\n",
    "    M = np.max(split_sizes)\n",
    "    \n",
    "    print('n components = {}'.format(n_components))\n",
    "    %timeit bins1(pts, indexes_inside_bins, M)\n",
    "    %timeit bins2(pts, indexes_inside_bins, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-netherlands",
   "metadata": {},
   "source": [
    "## Incidence of an `if` statement in a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-scott",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1():\n",
    "    for i in range(100000):\n",
    "        if i == -1:\n",
    "            print('this will never happen')\n",
    "        x = i*2-1\n",
    "        \n",
    "def f2():\n",
    "    for i in range(100000):\n",
    "        x = i*2-1\n",
    "        \n",
    "%timeit f1()\n",
    "%timeit f2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-hometown",
   "metadata": {},
   "source": [
    "## Is `np.nansum` faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((10000, 1000))\n",
    "x[1000:2000] = 4\n",
    "x[6000:8000] = 12\n",
    "\n",
    "%timeit np.sum(x)\n",
    "print(np.sum(x))\n",
    "\n",
    "y = np.full((10000, 1000), np.nan)\n",
    "y[1000:2000] = 4\n",
    "y[6000:8000] = 12\n",
    "\n",
    "%timeit np.nansum(y)\n",
    "print(np.nansum(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-tracker",
   "metadata": {},
   "source": [
    "## Fastest way to compute Hankel matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import sliding_window_view as swv\n",
    "\n",
    "def numpy_version(X, d):\n",
    "    n_ho_snapshots = X.shape[1] - d + 1\n",
    "\n",
    "    idxes = np.repeat(\n",
    "        np.arange(d)[None], repeats=n_ho_snapshots, axis=0\n",
    "    )\n",
    "    idxes += np.arange(n_ho_snapshots)[:,None]\n",
    "    return X.T[idxes].reshape(-1, X.shape[0] * d).T\n",
    "\n",
    "def numpy_version2(X, d):\n",
    "    n_ho_snapshots = X.shape[1] - d + 1\n",
    "\n",
    "    idxes = np.repeat(\n",
    "        np.arange(d)[None], repeats=n_ho_snapshots, axis=0\n",
    "    )\n",
    "    idxes += np.arange(n_ho_snapshots)[:,None]\n",
    "    return np.swapaxes(X[:,idxes],1,2).reshape(-1, X.shape[0] * d, order='F')\n",
    "\n",
    "def numpy_version3(X, d):\n",
    "    n_ho_snapshots = X.shape[1] - d + 1\n",
    "\n",
    "    idxes = np.repeat(\n",
    "        np.arange(d)[None], repeats=n_ho_snapshots, axis=0\n",
    "    )\n",
    "    idxes += np.arange(n_ho_snapshots)[:,None]\n",
    "    return np.swapaxes(X[:,idxes],0,1).reshape(-1, X.shape[0] * d).T\n",
    "\n",
    "def numpy_version3(X, d):\n",
    "    n_ho_snapshots = X.shape[1] - d + 1\n",
    "\n",
    "    idxes = np.repeat(\n",
    "        np.arange(d)[None], repeats=n_ho_snapshots, axis=0\n",
    "    )\n",
    "    idxes += np.arange(n_ho_snapshots)[:,None]\n",
    "    idxes = idxes.flatten()\n",
    "    return np.swapaxes(X[:,idxes],0,1).reshape(-1, X.shape[0] * d).T\n",
    "\n",
    "def numpy_version4(X, d):\n",
    "    n_ho_snapshots = X.shape[1] - d + 1\n",
    "\n",
    "    idxes = np.repeat(\n",
    "        np.arange(d)[None], repeats=n_ho_snapshots, axis=0\n",
    "    )\n",
    "    idxes += np.arange(n_ho_snapshots)[:,None]\n",
    "    return X[:, idxes.flatten()].reshape(X.shape[0] * d, -1, order='F')\n",
    "\n",
    "def stride_version(X, d):\n",
    "    n_ho_snapshots = X.shape[1] - d + 1\n",
    "    return swv(X, (X.shape[0], d))[0].reshape(n_ho_snapshots, -1, order='F').T\n",
    "\n",
    "def stride_version2(X, d):\n",
    "    n_ho_snapshots = X.shape[1] - d + 1\n",
    "    return swv(X.T, (d, X.shape[0]))[:,0].reshape(n_ho_snapshots, -1).T\n",
    "\n",
    "def python_list_version(X, d):\n",
    "    return np.concatenate(\n",
    "            [X[:, i : X.shape[1] - d + i + 1] for i in range(d)],\n",
    "            axis=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-canyon",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = np.ones((500, 1000))\n",
    "d = 10\n",
    "\n",
    "%timeit numpy_version(X,d)\n",
    "%timeit numpy_version2(X,d)\n",
    "%timeit numpy_version3(X,d)\n",
    "%timeit numpy_version4(X,d)\n",
    "%timeit stride_version(X,d)\n",
    "%timeit stride_version2(X,d)\n",
    "%timeit python_list_version(X,d)\n",
    "\n",
    "print('-----')\n",
    "\n",
    "X = np.ones((500, 1000))\n",
    "d = 100\n",
    "\n",
    "%timeit numpy_version(X,d)\n",
    "%timeit numpy_version2(X,d)\n",
    "%timeit numpy_version3(X,d)\n",
    "%timeit numpy_version4(X,d)\n",
    "%timeit stride_version(X,d)\n",
    "%timeit stride_version2(X,d)\n",
    "%timeit python_list_version(X,d)\n",
    "\n",
    "print('-----')\n",
    "\n",
    "X = np.ones((500, 10000))\n",
    "d = 100\n",
    "\n",
    "%timeit numpy_version(X,d)\n",
    "%timeit numpy_version2(X,d)\n",
    "%timeit numpy_version3(X,d)\n",
    "%timeit numpy_version4(X,d)\n",
    "%timeit stride_version(X,d)\n",
    "%timeit stride_version2(X,d)\n",
    "%timeit python_list_version(X,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-professional",
   "metadata": {},
   "source": [
    "## Transpose and `swapaxes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap(X):\n",
    "    if X.ndim == 3:\n",
    "        return np.swapaxes(X, 1,2).T\n",
    "    elif X.ndim == 4:\n",
    "        return np.swapaxes(np.swapaxes(np.swapaxes(X, 0,2), 2,3), 0,1)\n",
    "\n",
    "def swap2(X):\n",
    "    r = np.arange(X.ndim)\n",
    "    return np.moveaxis(X, r, np.roll(r, 1))\n",
    "\n",
    "shapes = [(20000,100,100,100), (200,10000,100,100), (200,100,10000,100), (200,100,100,10000)]\n",
    "for shape in shapes:\n",
    "    X = np.empty(shape)\n",
    "    print(X.shape)\n",
    "    %timeit swap(X)\n",
    "    %timeit swap2(X)\n",
    "    assert swap(X).shape == swap2(X).shape\n",
    "    del X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-birmingham",
   "metadata": {},
   "source": [
    "## Is using the `out` parameter faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(100000000).reshape(100, -1)\n",
    "%timeit y = np.clip(x, 100, 101)\n",
    "%timeit np.clip(x, 100, 101, out=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dfb4a3",
   "metadata": {},
   "source": [
    "## Shared memory in Dask?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7645dc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(processes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b99a420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_sm(idx, matrix):\n",
    "    matrix[idx] = idx\n",
    "\n",
    "def fill(idx, n_columns):\n",
    "    return np.repeat([idx], repeats=n_columns)[None]\n",
    "\n",
    "def fill_with_as_completed(rows, columns):\n",
    "    def fill(idx):\n",
    "        return idx, np.repeat([idx], repeats=columns)\n",
    "    \n",
    "    matrix=np.zeros((rows, columns))\n",
    "    futures = client.map(fill, range(rows))\n",
    "    for _, (row_idx, row) in as_completed(futures, with_results=True):\n",
    "        matrix[row_idx] = row\n",
    "\n",
    "M = 100\n",
    "N = 10000\n",
    "\n",
    "%timeit client.gather(client.map(fill_sm, range(M), matrix=np.zeros((M,N))));\n",
    "%timeit da.vstack([fill(i, N) for i in range(M)])\n",
    "%timeit fill_with_as_completed(M,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-failure",
   "metadata": {},
   "source": [
    "## Filling a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "latest-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by(a):\n",
    "    a = a[a[:, 0].argsort()]\n",
    "    return np.split(a[:, 1], np.unique(a[:, 0], return_index=True)[1][1:])\n",
    "\n",
    "# P is the number of covariates\n",
    "# k is the number of levels per covariate\n",
    "# n is the dimension of the sample\n",
    "def random_sample(P, n, k, probability_generator=None):\n",
    "    if probability_generator is None:\n",
    "\n",
    "        def probability_generator(arr):\n",
    "            return np.ones_like(arr) / len(arr)\n",
    "\n",
    "    ls = [None for p in range(P)]\n",
    "    for p in range(P):\n",
    "        arr = np.arange(k[p])\n",
    "        probabilities = probability_generator(arr)\n",
    "\n",
    "        # randomly select a level for each control value\n",
    "        choice = np.random.choice(arr, size=n, p=probabilities)\n",
    "        indexed_choices = np.hstack([choice[:, None], np.arange(n)[:, None]])\n",
    "        gb = group_by(indexed_choices)\n",
    "\n",
    "        un = np.unique(choice)\n",
    "        # add missing levels\n",
    "        i = 0\n",
    "        for u in un:\n",
    "            for j in range(i, u):\n",
    "                gb.insert(i, [])\n",
    "            i = u + 1\n",
    "        for j in range(i, k[p]):\n",
    "            gb.append([])\n",
    "\n",
    "        ls[p] = gb\n",
    "    return ls\n",
    "\n",
    "def random_Lprime(P, n_prime, k, probability_generator=None):\n",
    "    return random_sample(P, n_prime, k, probability_generator=probability_generator)\n",
    "\n",
    "def random_l(P, n, k, probability_generator=None):\n",
    "    ls = random_sample(P, n, k, probability_generator=probability_generator)\n",
    "    return list(map(lambda l: list(map(len, l)), ls))\n",
    "\n",
    "# with P=2\n",
    "def generate_problems(n, n_prime, k1, k2, probability_generator=None):\n",
    "    l = random_l(2, n, (k1, k2), probability_generator=probability_generator)\n",
    "    L_prime = random_Lprime(\n",
    "        2, n_prime, (k1, k2), probability_generator=probability_generator\n",
    "    )\n",
    "    return l, L_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "excellent-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_method(L_prime, k, n_prime):\n",
    "    csk = np.concatenate([[0], np.cumsum(k[:-1])])\n",
    "    shape = (csk[-1] + k[-1], n_prime)\n",
    "    \n",
    "    row_ind = np.concatenate([np.repeat(csk[p] + i, len(L_prime[p][i])) \n",
    "                              for p in range(len(L_prime)) for i in range(k[p])])\n",
    "    col_ind = np.concatenate([L_prime[p][i] for p in range(len(L_prime)) for i in range(k[p])])\n",
    "    data = np.ones_like(row_ind, dtype=int)\n",
    "    \n",
    "    return sparse.coo_matrix((data, (row_ind, col_ind)), shape=shape)\n",
    "\n",
    "def dense_method(L_prime, k, n_prime):\n",
    "    A = np.zeros((sum(k), n_prime), dtype=int)\n",
    "    current_row = 0\n",
    "    for p in range(len(L_prime)):\n",
    "        Lp_prime = L_prime[p]\n",
    "        for i in range(k[p]):\n",
    "            A[current_row, Lp_prime[i]] = 1\n",
    "            current_row += 1\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [100, 50]\n",
    "n, n_prime = 10000, 100000\n",
    "l, L_prime = generate_problems(n, n_prime, *k)\n",
    "\n",
    "A_sparse = sparse_method(L_prime, k, n_prime).toarray()\n",
    "A_dense = dense_method(L_prime, k, n_prime)\n",
    "np.testing.assert_almost_equal(A_sparse, A_dense)\n",
    "\n",
    "%timeit sparse_method(L_prime, k, n_prime)\n",
    "%timeit sparse_method(L_prime, k, n_prime).toarray()\n",
    "%timeit sparse_method(L_prime, k, n_prime).tocsc()\n",
    "%timeit sparse_method(L_prime, k, n_prime).tocsr()\n",
    "print('----')\n",
    "%timeit sparse_method_csc(L_prime, k, n_prime)\n",
    "%timeit sparse_method_csr(L_prime, k, n_prime)\n",
    "print('----')\n",
    "%timeit dense_method(L_prime, k, n_prime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-output",
   "metadata": {},
   "source": [
    "## Computing matrix `U` \n",
    "### From the paper *Network flow methods for the minimum covariate imbalance problem*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "durable-shark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_compute_U(A, k0):\n",
    "    A1 = A[:k0]\n",
    "    A2 = A[k0:]\n",
    "    return A1.dot(A2.T).toarray()\n",
    "\n",
    "def sparse_compute_U2(A, k0):\n",
    "    positive_A = (A > 0).toarray()\n",
    "    A1 = positive_A[: k0]\n",
    "    A2 = positive_A[k0 :]\n",
    "    return np.count_nonzero(\n",
    "        np.logical_and(A1[:, None], A2[None]), \n",
    "        axis=-1)\n",
    "\n",
    "def dense_compute_U(A, k0):\n",
    "    A1 = A[: k0] > 0\n",
    "    A2 = A[k0 :] > 0\n",
    "    return np.count_nonzero(\n",
    "        np.logical_and(A1[:, None], A2[None]), \n",
    "        axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "demanding-bankruptcy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.02 ms ± 196 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "4 s ± 319 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "4.47 s ± 544 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "k = [100, 200]\n",
    "n, n_prime = 10000, 100000\n",
    "l, L_prime = generate_problems(n, n_prime, *k)\n",
    "\n",
    "A_sparse = sparse_method(L_prime, k, n_prime).tocsr()\n",
    "A_dense = dense_method(L_prime, k, n_prime)\n",
    "\n",
    "%timeit sparse_compute_U(A_sparse, k[0])\n",
    "%timeit sparse_compute_U2(A_sparse, k[0])\n",
    "%timeit dense_compute_U(A_dense, k[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "restricted-senior",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c57ce2dd68ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA_sparse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_sparse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mA_dense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mtimes_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprime_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mtimes_matrix\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-c57ce2dd68ca>\u001b[0m in \u001b[0;36mbenchmark\u001b[0;34m(func, A, k)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-18107957cb6f>\u001b[0m in \u001b[0;36msparse_compute_U2\u001b[0;34m(A, k0)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mA2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositive_A\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     return np.count_nonzero(\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         axis=-1)\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from itertools import product\n",
    "\n",
    "def benchmark(func, A, k):\n",
    "    start = time()\n",
    "    func(A, k)\n",
    "    return time() - start\n",
    "\n",
    "def generate_sparsedense_A(k, nprime):\n",
    "    n = 10\n",
    "    k = (k,k)\n",
    "    l, L_prime = generate_problems(n, nprime, *k)\n",
    "\n",
    "    A_sparse = sparse_method(L_prime, k, n_prime).tocsr()\n",
    "    A_dense = dense_method(L_prime, k, n_prime)\n",
    "    \n",
    "    return A_sparse, A_dense\n",
    "\n",
    "ks = [10, 100, 1000, 10000]\n",
    "nprimes = [10, 100, 1000, 10000]\n",
    "times = 5\n",
    "\n",
    "funcs = [dense_compute_U, sparse_compute_U2, sparse_compute_U]\n",
    "is_sparse = [False, True, True]\n",
    "times_matrix = np.zeros((len(funcs), len(ks), len(nprimes)), dtype=float)\n",
    "for k, k_idx, nprime, nprime_idx in product(ks, range(len(ks)), nprimes, range(len(nprimes))):\n",
    "    A_sparse, A_dense = generate_problem(k, nprime)\n",
    "    \n",
    "    for func_idx, func in enumerate(funcs):\n",
    "        A = A_sparse if is_sparse[func_idx] else A_dense\n",
    "        for _ in range(times):\n",
    "            times_matrix[func_idx, k_idx, nprime_idx] += benchmark(func, A, k)\n",
    "times_matrix /= times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-muslim",
   "metadata": {},
   "source": [
    "## Generating a 2D grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fatty-constraint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252 µs ± 6.93 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "137 µs ± 8.09 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def grid_1(N):\n",
    "    x = np.linspace(-5, 5, N)\n",
    "    y = np.linspace(-5, 5, N)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    return np.dstack(np.meshgrid(x,y))\n",
    "\n",
    "def grid_2(N):\n",
    "    step = 10 / (N - 1)\n",
    "    return (np.mgrid[:N, :N] * step - 5).T\n",
    "\n",
    "np.testing.assert_allclose(grid_1(int(1.e2)), grid_2(int(1.e2)))\n",
    "\n",
    "%timeit grid_1(int(1.e2))\n",
    "%timeit grid_2(int(1.e2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-walnut",
   "metadata": {},
   "source": [
    "## Is `slice` faster than `[:]`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adjusted-brooklyn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D\n",
      "299 ns ± 15.2 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "409 ns ± 5.45 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "2D\n",
      "456 ns ± 8.66 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "702 ns ± 4.94 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "3D\n",
      "550 ns ± 18.6 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "887 ns ± 7.51 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(100000000).reshape(500, 100, -1)\n",
    "print('1D')\n",
    "%timeit x[100:498]\n",
    "%timeit x[slice(100,498)]\n",
    "print('2D')\n",
    "%timeit x[100:498, 8:90]\n",
    "%timeit x[slice(100,498), slice(8,90)]\n",
    "print('3D')\n",
    "%timeit x[100:498, 8:90, 1000:1800]\n",
    "%timeit x[slice(100,498), slice(8,90), slice(1000,1800)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-albany",
   "metadata": {},
   "source": [
    "## Is `np.empty` faster than `np.zeros`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "postal-coating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.51 µs ± 20.2 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "17.4 ms ± 244 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "17.3 ms ± 176 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.empty((10000, 100, 10))\n",
    "%timeit np.zeros((10000, 100, 10), dtype=int)\n",
    "%timeit np.zeros((10000, 100, 10), dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-think",
   "metadata": {},
   "source": [
    "## What if we have a mask of values to initialize to something?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "satellite-circulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.5 ms ± 881 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "22.5 ms ± 1.29 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "u = np.random.rand(1000000, 2)\n",
    "point = np.array([0.75, 0.75])\n",
    "d = 0.3\n",
    "\n",
    "def function(x):\n",
    "    return np.power(x, 2)\n",
    "\n",
    "distances = np.linalg.norm(u - point[None], axis=-1)\n",
    "nearby = distances < d\n",
    "\n",
    "def with_empty():\n",
    "    nnearby = np.logical_not(nearby)\n",
    "    \n",
    "    mapped_distance = np.empty_like(distances, dtype=float)\n",
    "    mapped_distance[nearby] = function(distances[nearby])\n",
    "    mapped_distance[nnearby] = 0\n",
    "    return mapped_distance\n",
    "\n",
    "def without_empty():\n",
    "    mapped_distance = np.zeros_like(distances, dtype=float)\n",
    "    mapped_distance[nearby] = function(distances[nearby])\n",
    "    return mapped_distance\n",
    "\n",
    "np.testing.assert_allclose(with_empty(), without_empty())\n",
    "\n",
    "%timeit with_empty()\n",
    "%timeit without_empty()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-attraction",
   "metadata": {},
   "source": [
    "## Should we recycle the distance matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "promotional-following",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.5 ms ± 1.17 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "16.2 ms ± 99.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "def recycle(dst):\n",
    "    dst[nearby] = function(dst[nearby])\n",
    "    dst[np.logical_not(nearby)] = 0\n",
    "    return dst\n",
    "\n",
    "def waste(dst):\n",
    "    mapped_distance = np.zeros_like(dst, dtype=float)\n",
    "    mapped_distance[nearby] = function(dst[nearby])\n",
    "    return mapped_distance\n",
    "\n",
    "distances = np.linalg.norm(u - point[None], axis=-1)\n",
    "np.testing.assert_allclose(waste(distances), recycle(distances))\n",
    "distances = np.linalg.norm(u - point[None], axis=-1)\n",
    "\n",
    "%timeit recycle(distances)\n",
    "%timeit waste(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-microphone",
   "metadata": {},
   "source": [
    "## Is writing in slices more efficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "favorite-syndrome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.75 ms ± 162 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "15.2 ms ± 9.68 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((100000, 1000))\n",
    "\n",
    "%timeit x[:10000] = 4\n",
    "\n",
    "idxes = np.arange(10000, 20000)\n",
    "%timeit x[idxes] = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-wireless",
   "metadata": {},
   "source": [
    "## Periodic write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_sliding_window(arr, write, lower_bounds, upper_bounds):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
