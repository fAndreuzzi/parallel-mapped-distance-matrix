{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ancient-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dask.array as da\n",
    "from dask.distributed import Client, as_completed\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-display",
   "metadata": {},
   "source": [
    "# PLEASE\n",
    "Run only what you need. Thanks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-privilege",
   "metadata": {},
   "source": [
    "## Simultaneous max and min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(x):\n",
    "    y = np.max(x[:, None, :] * np.array([-1, 1])[:, None, None], axis=2)\n",
    "    #y[:, 0] *= -1\n",
    "    return y\n",
    "\n",
    "def minmax2(x):\n",
    "    return np.concatenate([np.min(x, axis=1)[:,None], np.max(x, axis=1)[:,None]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-stadium",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10000000).reshape(-1,50,2)\n",
    "\n",
    "#assert np.allclose(minmax(x), minmax2(x))\n",
    "\n",
    "%timeit minmax(x)\n",
    "%timeit minmax2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-sacramento",
   "metadata": {},
   "source": [
    "## `np.nan` is as performant as a shorter matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1000000).reshape(-1,2)\n",
    "print(x.shape)\n",
    "\n",
    "%timeit x + 2 - np.array([2,20])[None]\n",
    "\n",
    "y = np.vstack([x, np.full((500000, 2), np.nan)])\n",
    "print(y.shape)\n",
    "\n",
    "%timeit y + 2 - np.array([2,20])[None]\n",
    "\n",
    "z = np.vstack([x, x])\n",
    "print(z.shape)\n",
    "\n",
    "%timeit z + 2 - np.array([2,20])[None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-establishment",
   "metadata": {},
   "source": [
    "## Best way to achieve all `False` in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.full((10000,1000), False)\n",
    "x[2,5] = True\n",
    "x[1000,10] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit np.all(np.logical_not(x), axis=1)\n",
    "%timeit np.logical_not(np.any(x, axis=1))\n",
    "%timeit ~np.any(x, axis=1)\n",
    "%timeit (~x).all(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-patch",
   "metadata": {},
   "source": [
    "## Is `map_blocks` better than the standard operation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-disaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = da.from_array(np.ones((1000,1000,200)))\n",
    "\n",
    "print('Simple subtraction')\n",
    "%timeit (y - 10).compute()\n",
    "%timeit y.map_blocks(lambda x: x - 10).compute()\n",
    "\n",
    "print('Some references to y')\n",
    "%timeit (y - 10 + 2*y).compute()\n",
    "%timeit y.map_blocks(lambda x: x - 10 + 2*x).compute()\n",
    "\n",
    "print('Multiple references to y')\n",
    "%timeit (y + 2*y - 3*y + 4*y - 5*y).compute()\n",
    "%timeit y.map_blocks(lambda x: x + 2*x - 3*x + 4*x - 5*x).compute()\n",
    "\n",
    "print('NumPy function')\n",
    "%timeit (np.exp(y+2)).compute()\n",
    "%timeit y.map_blocks(lambda x: np.exp(x)).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-integrity",
   "metadata": {},
   "source": [
    "## Is `map_blocks` better/worse than the corresponding Dask function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = da.from_array(np.ones((1000,1000,20)) + 0.5)\n",
    "\n",
    "%timeit y.map_blocks(lambda x: np.floor(x)).compute()\n",
    "%timeit da.floor(y).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-texas",
   "metadata": {},
   "source": [
    "## Does `np.unique` work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-valley",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = da.from_array(np.arange(10000))\n",
    "da.unique(y, return_index=True)[1].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-backup",
   "metadata": {},
   "source": [
    "## What about `argsort`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = da.from_array(np.arange(10000))\n",
    "y = y[da.argsort(y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-license",
   "metadata": {},
   "source": [
    "## What's the best way to create a matrix such that different submatrices are filled with different rules?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill1():\n",
    "    x = np.zeros((9900, 100), dtype=float)\n",
    "    for i in range(1,100):\n",
    "        x[(i-1)*100:i*100] = i*np.arange(i*100-100,i*100)[::-1]\n",
    "    return x\n",
    "\n",
    "def fill2():\n",
    "    return np.vstack([\n",
    "        np.repeat(i*np.arange(i*100-100,i*100)[::-1][None], repeats=100, axis=0) for i in range(1,100)\n",
    "    ])\n",
    "\n",
    "\n",
    "%timeit fill1()\n",
    "%timeit fill2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-southeast",
   "metadata": {},
   "source": [
    "## What's the best way to fill a matrix taking values from a vector according to some indexing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def generate_binified_points_matrix(pts, indexes, bins_size):\n",
    "    zs = np.zeros((bins_size - 1, pts.shape[1]))\n",
    "    for idx in range(len(indexes)):\n",
    "        idx = indexes[idx]\n",
    "        yield pts[idx], zs[: bins_size - len(idx)]\n",
    "        \n",
    "def bins1(pts, indexes_inside_bins, biggest_bin):\n",
    "    return np.vstack(\n",
    "            tuple(chain.from_iterable(\n",
    "                generate_binified_points_matrix(\n",
    "                    pts, indexes_inside_bins, biggest_bin\n",
    "                )\n",
    "            ))\n",
    "        ).reshape(len(indexes_inside_bins), biggest_bin, pts.shape[1])\n",
    "\n",
    "def bins2(pts, indexes_inside_bins, biggest_bin):\n",
    "    nbins = len(indexes_inside_bins)\n",
    "    bins = np.zeros((nbins, biggest_bin, pts.shape[1]))\n",
    "    for bin_idx in range(nbins):\n",
    "        ps = pts[indexes_inside_bins[bin_idx]]\n",
    "        bins[bin_idx, : len(ps)] = ps\n",
    "    return bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_components in (1,2,3,5,10,100):\n",
    "    pts = np.random.rand(10000, n_components)\n",
    "    indexes_inside_bins = np.arange(10000)[::-1]\n",
    "    split_sizes = [100,200,400,50, 50, 1000, 1500, 500, 900, 100, 500, 1000, 500, 100, 200, 200, \n",
    "                   500, 1000, 1, 1, 1, 7, 80, 5]\n",
    "    indexes_inside_bins = np.split(indexes_inside_bins, np.cumsum(split_sizes))\n",
    "\n",
    "    M = np.max(split_sizes)\n",
    "    \n",
    "    print('n components = {}'.format(n_components))\n",
    "    %timeit bins1(pts, indexes_inside_bins, M)\n",
    "    %timeit bins2(pts, indexes_inside_bins, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-netherlands",
   "metadata": {},
   "source": [
    "## Incidence of an `if` statement in a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-scott",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1():\n",
    "    for i in range(100000):\n",
    "        if i == -1:\n",
    "            print('this will never happen')\n",
    "        x = i*2-1\n",
    "        \n",
    "def f2():\n",
    "    for i in range(100000):\n",
    "        x = i*2-1\n",
    "        \n",
    "%timeit f1()\n",
    "%timeit f2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-hometown",
   "metadata": {},
   "source": [
    "## Is `np.nansum` faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((10000, 1000))\n",
    "x[1000:2000] = 4\n",
    "x[6000:8000] = 12\n",
    "\n",
    "%timeit np.sum(x)\n",
    "print(np.sum(x))\n",
    "\n",
    "y = np.full((10000, 1000), np.nan)\n",
    "y[1000:2000] = 4\n",
    "y[6000:8000] = 12\n",
    "\n",
    "%timeit np.nansum(y)\n",
    "print(np.nansum(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-tracker",
   "metadata": {},
   "source": [
    "## Fastest way to compute Hankel matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import sliding_window_view as swv\n",
    "\n",
    "def numpy_version(X, d):\n",
    "    n_ho_snapshots = X.shape[1] - d + 1\n",
    "\n",
    "    idxes = np.repeat(\n",
    "        np.arange(d)[None], repeats=n_ho_snapshots, axis=0\n",
    "    )\n",
    "    idxes += np.arange(n_ho_snapshots)[:,None]\n",
    "    return X.T[idxes].reshape(-1, X.shape[0] * d).T\n",
    "\n",
    "def numpy_version2(X, d):\n",
    "    n_ho_snapshots = X.shape[1] - d + 1\n",
    "\n",
    "    idxes = np.repeat(\n",
    "        np.arange(d)[None], repeats=n_ho_snapshots, axis=0\n",
    "    )\n",
    "    idxes += np.arange(n_ho_snapshots)[:,None]\n",
    "    return np.swapaxes(X[:,idxes],1,2).reshape(-1, X.shape[0] * d, order='F')\n",
    "\n",
    "def numpy_version3(X, d):\n",
    "    n_ho_snapshots = X.shape[1] - d + 1\n",
    "\n",
    "    idxes = np.repeat(\n",
    "        np.arange(d)[None], repeats=n_ho_snapshots, axis=0\n",
    "    )\n",
    "    idxes += np.arange(n_ho_snapshots)[:,None]\n",
    "    return np.swapaxes(X[:,idxes],0,1).reshape(-1, X.shape[0] * d).T\n",
    "\n",
    "def numpy_version3(X, d):\n",
    "    n_ho_snapshots = X.shape[1] - d + 1\n",
    "\n",
    "    idxes = np.repeat(\n",
    "        np.arange(d)[None], repeats=n_ho_snapshots, axis=0\n",
    "    )\n",
    "    idxes += np.arange(n_ho_snapshots)[:,None]\n",
    "    idxes = idxes.flatten()\n",
    "    return np.swapaxes(X[:,idxes],0,1).reshape(-1, X.shape[0] * d).T\n",
    "\n",
    "def numpy_version4(X, d):\n",
    "    n_ho_snapshots = X.shape[1] - d + 1\n",
    "\n",
    "    idxes = np.repeat(\n",
    "        np.arange(d)[None], repeats=n_ho_snapshots, axis=0\n",
    "    )\n",
    "    idxes += np.arange(n_ho_snapshots)[:,None]\n",
    "    return X[:, idxes.flatten()].reshape(X.shape[0] * d, -1, order='F')\n",
    "\n",
    "def stride_version(X, d):\n",
    "    n_ho_snapshots = X.shape[1] - d + 1\n",
    "    return swv(X, (X.shape[0], d))[0].reshape(n_ho_snapshots, -1, order='F').T\n",
    "\n",
    "def stride_version2(X, d):\n",
    "    n_ho_snapshots = X.shape[1] - d + 1\n",
    "    return swv(X.T, (d, X.shape[0]))[:,0].reshape(n_ho_snapshots, -1).T\n",
    "\n",
    "def python_list_version(X, d):\n",
    "    return np.concatenate(\n",
    "            [X[:, i : X.shape[1] - d + i + 1] for i in range(d)],\n",
    "            axis=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-canyon",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = np.ones((500, 1000))\n",
    "d = 10\n",
    "\n",
    "%timeit numpy_version(X,d)\n",
    "%timeit numpy_version2(X,d)\n",
    "%timeit numpy_version3(X,d)\n",
    "%timeit numpy_version4(X,d)\n",
    "%timeit stride_version(X,d)\n",
    "%timeit stride_version2(X,d)\n",
    "%timeit python_list_version(X,d)\n",
    "\n",
    "print('-----')\n",
    "\n",
    "X = np.ones((500, 1000))\n",
    "d = 100\n",
    "\n",
    "%timeit numpy_version(X,d)\n",
    "%timeit numpy_version2(X,d)\n",
    "%timeit numpy_version3(X,d)\n",
    "%timeit numpy_version4(X,d)\n",
    "%timeit stride_version(X,d)\n",
    "%timeit stride_version2(X,d)\n",
    "%timeit python_list_version(X,d)\n",
    "\n",
    "print('-----')\n",
    "\n",
    "X = np.ones((500, 10000))\n",
    "d = 100\n",
    "\n",
    "%timeit numpy_version(X,d)\n",
    "%timeit numpy_version2(X,d)\n",
    "%timeit numpy_version3(X,d)\n",
    "%timeit numpy_version4(X,d)\n",
    "%timeit stride_version(X,d)\n",
    "%timeit stride_version2(X,d)\n",
    "%timeit python_list_version(X,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-professional",
   "metadata": {},
   "source": [
    "## Transpose and `swapaxes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap(X):\n",
    "    if X.ndim == 3:\n",
    "        return np.swapaxes(X, 1,2).T\n",
    "    elif X.ndim == 4:\n",
    "        return np.swapaxes(np.swapaxes(np.swapaxes(X, 0,2), 2,3), 0,1)\n",
    "\n",
    "def swap2(X):\n",
    "    r = np.arange(X.ndim)\n",
    "    return np.moveaxis(X, r, np.roll(r, 1))\n",
    "\n",
    "shapes = [(20000,100,100,100), (200,10000,100,100), (200,100,10000,100), (200,100,100,10000)]\n",
    "for shape in shapes:\n",
    "    X = np.empty(shape)\n",
    "    print(X.shape)\n",
    "    %timeit swap(X)\n",
    "    %timeit swap2(X)\n",
    "    assert swap(X).shape == swap2(X).shape\n",
    "    del X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-birmingham",
   "metadata": {},
   "source": [
    "## Is using the `out` parameter faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(100000000).reshape(100, -1)\n",
    "%timeit y = np.clip(x, 100, 101)\n",
    "%timeit np.clip(x, 100, 101, out=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dfb4a3",
   "metadata": {},
   "source": [
    "## Shared memory in Dask?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7645dc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(processes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b99a420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_sm(idx, matrix):\n",
    "    matrix[idx] = idx\n",
    "\n",
    "def fill(idx, n_columns):\n",
    "    return np.repeat([idx], repeats=n_columns)[None]\n",
    "\n",
    "def fill_with_as_completed(rows, columns):\n",
    "    def fill(idx):\n",
    "        return idx, np.repeat([idx], repeats=columns)\n",
    "    \n",
    "    matrix=np.zeros((rows, columns))\n",
    "    futures = client.map(fill, range(rows))\n",
    "    for _, (row_idx, row) in as_completed(futures, with_results=True):\n",
    "        matrix[row_idx] = row\n",
    "\n",
    "M = 100\n",
    "N = 10000\n",
    "\n",
    "%timeit client.gather(client.map(fill_sm, range(M), matrix=np.zeros((M,N))));\n",
    "%timeit da.vstack([fill(i, N) for i in range(M)])\n",
    "%timeit fill_with_as_completed(M,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-failure",
   "metadata": {},
   "source": [
    "## Filling a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "latest-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by(a):\n",
    "    a = a[a[:, 0].argsort()]\n",
    "    return np.split(a[:, 1], np.unique(a[:, 0], return_index=True)[1][1:])\n",
    "\n",
    "# P is the number of covariates\n",
    "# k is the number of levels per covariate\n",
    "# n is the dimension of the sample\n",
    "def random_sample(P, n, k, probability_generator=None):\n",
    "    if probability_generator is None:\n",
    "\n",
    "        def probability_generator(arr):\n",
    "            return np.ones_like(arr) / len(arr)\n",
    "\n",
    "    ls = [None for p in range(P)]\n",
    "    for p in range(P):\n",
    "        arr = np.arange(k[p])\n",
    "        probabilities = probability_generator(arr)\n",
    "\n",
    "        # randomly select a level for each control value\n",
    "        choice = np.random.choice(arr, size=n, p=probabilities)\n",
    "        indexed_choices = np.hstack([choice[:, None], np.arange(n)[:, None]])\n",
    "        gb = group_by(indexed_choices)\n",
    "\n",
    "        un = np.unique(choice)\n",
    "        # add missing levels\n",
    "        i = 0\n",
    "        for u in un:\n",
    "            for j in range(i, u):\n",
    "                gb.insert(i, [])\n",
    "            i = u + 1\n",
    "        for j in range(i, k[p]):\n",
    "            gb.append([])\n",
    "\n",
    "        ls[p] = gb\n",
    "    return ls\n",
    "\n",
    "def random_Lprime(P, n_prime, k, probability_generator=None):\n",
    "    return random_sample(P, n_prime, k, probability_generator=probability_generator)\n",
    "\n",
    "def random_l(P, n, k, probability_generator=None):\n",
    "    ls = random_sample(P, n, k, probability_generator=probability_generator)\n",
    "    return list(map(lambda l: list(map(len, l)), ls))\n",
    "\n",
    "# with P=2\n",
    "def generate_problems(n, n_prime, k1, k2, probability_generator=None):\n",
    "    l = random_l(2, n, (k1, k2), probability_generator=probability_generator)\n",
    "    L_prime = random_Lprime(\n",
    "        2, n_prime, (k1, k2), probability_generator=probability_generator\n",
    "    )\n",
    "    return l, L_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "excellent-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_method(L_prime, k, n_prime):\n",
    "    csk = np.concatenate([[0], np.cumsum(k[:-1])])\n",
    "    shape = (csk[-1] + k[-1], n_prime)\n",
    "    \n",
    "    row_ind = np.concatenate([np.repeat(csk[p] + i, len(L_prime[p][i])) \n",
    "                              for p in range(len(L_prime)) for i in range(k[p])])\n",
    "    col_ind = np.concatenate([L_prime[p][i] for p in range(len(L_prime)) for i in range(k[p])])\n",
    "    data = np.ones_like(row_ind, dtype=int)\n",
    "    \n",
    "    return sparse.coo_matrix((data, (row_ind, col_ind)), shape=shape)\n",
    "\n",
    "def dense_method(L_prime, k, n_prime):\n",
    "    A = np.zeros((sum(k), n_prime), dtype=int)\n",
    "    current_row = 0\n",
    "    for p in range(len(L_prime)):\n",
    "        Lp_prime = L_prime[p]\n",
    "        for i in range(k[p]):\n",
    "            A[current_row, Lp_prime[i]] = 1\n",
    "            current_row += 1\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cardiac-surgery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.1 ms ± 1.07 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "36.5 ms ± 972 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "12.1 ms ± 1.26 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "22.3 ms ± 529 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "----\n",
      "13.9 ms ± 2.18 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "29.6 ms ± 6.86 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "----\n",
      "72.8 ms ± 29.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "k = [100, 50]\n",
    "n, n_prime = 10000, 100000\n",
    "l, L_prime = generate_problems(n, n_prime, *k)\n",
    "\n",
    "A_sparse = sparse_method(L_prime, k, n_prime).toarray()\n",
    "A_dense = dense_method(L_prime, k, n_prime)\n",
    "np.testing.assert_almost_equal(A_sparse, A_dense)\n",
    "\n",
    "%timeit sparse_method(L_prime, k, n_prime)\n",
    "%timeit sparse_method(L_prime, k, n_prime).toarray()\n",
    "%timeit sparse_method(L_prime, k, n_prime).tocsc()\n",
    "%timeit sparse_method(L_prime, k, n_prime).tocsr()\n",
    "print('----')\n",
    "%timeit sparse_method_csc(L_prime, k, n_prime)\n",
    "%timeit sparse_method_csr(L_prime, k, n_prime)\n",
    "print('----')\n",
    "%timeit dense_method(L_prime, k, n_prime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
